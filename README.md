# FundingMatch AI - Intelligent Investment Matching System

## ğŸš€ Project Overview

FundingMatch AI is an AI-powered intelligent investment matching system that uses multi-dimensional analysis and machine learning technology to recommend the most suitable investment institutions for startups.

## âœ¨ Core Features

- **Intelligent Investment Matching**: Semantic search-based investment institution recommendations
- **Risk Assessment**: Machine learning-driven investment success probability prediction
- **Market Intelligence**: Real-time market trends and industry analysis
- **Smart Conversation**: Natural language interaction for investment consultation

## ğŸ—ï¸ Technical Architecture

- **AI Agent**: Intelligent agent system based on LangChain
- **Vector Database**: ChromaDB for semantic search implementation
- **Machine Learning**: Integration of multiple ML models for risk assessment
- **Web Interface**: User-friendly interface built with Streamlit
- **LLM Integration**: Support for OpenAI and DeepSeek models

## ğŸ“‹ System Requirements

- Python 3.8+
- 8GB+ RAM
- Stable internet connection

## ğŸ› ï¸ Installation Steps

### 1. Clone the Project
```bash
git clone https://github.com/yourusername/Funding_Agent_V3.git
cd Funding_Agent_V3
```

### 2. Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
# or
venv\Scripts\activate  # Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Environment Variables Configuration

#### Method 1: Create .env File (Recommended)
Create a `.env` file in the project root directory:

```bash
# LLM Provider Configuration
LLM_PROVIDER=openai  # or deepseek
LLM_MODEL=gpt-4o-mini  # OpenAI model name

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# DeepSeek Configuration
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Other API Configuration
TAVILY_API_KEY=your_tavily_api_key_here
SERPER_API_KEY=your_serper_api_key_here
```

#### Method 2: System Environment Variables
```bash
export LLM_PROVIDER=openai
export OPENAI_API_KEY=your_openai_api_key_here
export LLM_MODEL=gpt-4o-mini
```

### 5. Run the Application
```bash
streamlit run app.py
```

## ğŸ”§ Configuration Guide

### LLM Provider Switching

The system supports two LLM providers:

1. **OpenAI** (Recommended for Production)
   - Models: GPT-4o-mini, GPT-4
   - Advantages: Stable performance, powerful features
   - Use Case: Production deployment and advanced features

2. **DeepSeek** (Recommended for Development/Testing)
   - Models: deepseek-chat
   - Advantages: Lower cost, suitable for development testing
   - Use Case: Feature validation and cost control

### Switching Methods

```python
# Specify in code
agent = SmartFundingAgent(llm_provider="openai", llm_model="gpt-4o-mini")

# Or through environment variables
export LLM_PROVIDER=openai
export LLM_MODEL=gpt-4o-mini
```

## ğŸ“ Project Structure

```
Funding_Agent_V3/
â”œâ”€â”€ app.py                 # Streamlit main application
â”œâ”€â”€ agents/               # AI agent modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ funding_agent.py  # Core intelligent agent
â”œâ”€â”€ tools/                # Tool modules
â”‚   â”œâ”€â”€ funding_rag_tool.py    # Investment matching tool
â”‚   â”œâ”€â”€ risk_predict_tool.py   # Risk assessment tool
â”‚   â””â”€â”€ web_search_tool.py     # Web search tool
â”œâ”€â”€ data/                 # Data files
â”‚   â””â”€â”€ eu_investors_all_countries.csv
â”œâ”€â”€ models/               # Machine learning models
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env                 # Environment variables (not committed to Git)
â”œâ”€â”€ .gitignore          # Git ignore file
â””â”€â”€ README.md           # Project documentation
```

## ğŸš€ Deploy to Streamlit Community Cloud

### 1. Prepare for Deployment
Ensure your code has been pushed to GitHub repository and contains:
- `requirements.txt`
- `app.py` as the main file
- No `.env` file (excluded via .gitignore)

### 2. Deployment Steps
1. Visit [Streamlit Community Cloud](https://share.streamlit.io/)
2. Login with your GitHub account
3. Select your repository
4. Configure deployment settings:
   - **Main file path**: `app.py`
   - **Python version**: 3.8+
5. Add environment variables in "Advanced settings":
   - `LLM_PROVIDER`
   - `OPENAI_API_KEY`
   - `LLM_MODEL`
   - Other necessary API keys

### 3. Environment Variables Setup
In Streamlit Community Cloud deployment settings, add all necessary environment variables to ensure consistency with your local `.env` file configuration.

## ğŸ”’ Security Considerations

- **Never** commit `.env` files to Git repositories
- Regularly rotate API keys
- Use strong passwords and secure API keys in production environments
- Monitor API usage and costs

## ğŸ› Frequently Asked Questions

### Q: Why does the system display "Typical Investment: N/A"?
A: Check if the column names in the data file match the metadata keys in the code.

### Q: How to resolve LLM model switching issues?
A: Ensure environment variables are correctly set and verify API key validity.

### Q: What if the system enters an infinite loop?
A: Check Streamlit session state management and ensure button logic is correct.

## ğŸ“Š Performance Optimization

- Enable vector database caching
- Use appropriate LLM models (DeepSeek for development, OpenAI for production)
- Optimize query strategies and tool calling order

## ğŸ¤ Contributing

Welcome to submit Issues and Pull Requests!

